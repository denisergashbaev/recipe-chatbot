{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import litellm\n",
    "from typing import Final\n",
    "from dotenv import load_dotenv\n",
    "from textwrap import dedent, wrap\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "\n",
    "class Dimention(BaseModel):\n",
    "    meal_type: str = Field(..., description=\"The type of meal the user is interested in, such as 'Lite breakfast', 'Brunch'\")\n",
    "    dietary_restriction: str = Field(..., description=\"The dietary restrictions the user has, such as 'Not spicy', 'without fish or meat'\")\n",
    "    preparation_time: str = Field(..., description=\"The preparation time the user is interested in, such as '10 minutes', 'something quick', 'under 1 hour'\")\n",
    "\n",
    "    @classmethod\n",
    "    def get_prompt_description(cls) -> str:\n",
    "        description = []\n",
    "        for field_name, field_info in cls.model_fields.items():\n",
    "            description.append(f\"- {field_name}: {field_info.description}\")\n",
    "        return \"\\n\".join(description)\n",
    "\n",
    "\n",
    "num_dimention_instances: Final[int] = 50\n",
    "\n",
    "\n",
    "class DimentionList(BaseModel):\n",
    "    dimention_list: list[Dimention] = Field(\n",
    "        ..., \n",
    "        description=f\"List of dimention instances, there should be {num_dimention_instances} instances in the list\", \n",
    "        default_factory=list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gemini/gemini-2.5-flash'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME: Final[str] = os.environ[\"MODEL_NAME\"]\n",
    "MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('gemini-2.5-flash', 'gemini', None, None)\n",
      "['temperature', 'top_p', 'max_tokens', 'max_completion_tokens', 'stream', 'tools', 'tool_choice', 'functions', 'response_format', 'n', 'stop', 'logprobs', 'frequency_penalty', 'modalities', 'parallel_tool_calls', 'web_search_options', 'reasoning_effort', 'thinking']\n"
     ]
    }
   ],
   "source": [
    "from litellm import get_supported_openai_params\n",
    "\n",
    "params = get_supported_openai_params(model=MODEL_NAME)\n",
    "\n",
    "custom_llm_provider = litellm.get_llm_provider(model=MODEL_NAME)\n",
    "\n",
    "print(custom_llm_provider)\n",
    "\n",
    "assert \"response_format\" in params\n",
    "\n",
    "print(params)\n",
    "\n",
    "from litellm import supports_response_schema\n",
    "\n",
    "assert supports_response_schema(model=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dimention_list(dimention_list: str):\n",
    "    SYSTEM_PROMPT = dedent(f\"\"\"\n",
    "        You are AI assistant that helps generate instances for dimentions of the queries that will be sent to the recipe chatbot. A dimention describes aspects of the query that that the users send to the chatbot. \n",
    "        Given following dimention types, generate tuple combinations of the dimentions\n",
    "\n",
    "        Dimentions:\n",
    "            meal_type: The type of meal the user is interested in, such as 'Lite breakfast', 'Brunch'\n",
    "            dietary_restriction: The dietary restrictions the user has, such as 'Not spicy', 'without fish or meat', 'meaty'\n",
    "            preparation_time: The preparation time the user is interested in, such as '10 minutes', 'something quick', 'under 1 hour', 'I haveall the time until retirement'\n",
    "\n",
    "        Instructions:\n",
    "            - Generate  {num_dimention_instances} tuple combinations of the dimentions.\n",
    "            - Avoid duplicates. \n",
    "            - Make sure that the tuples are diverse. \n",
    "\n",
    "        Example output:\n",
    "        - ('Lite breakfast', 'Not spicy', '10 minutes')\n",
    "        - ('Snack', 'with hummus and carrots', 'instant')\n",
    "    \"\"\")\n",
    "    completion = litellm.completion(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": SYSTEM_PROMPT}\n",
    "        ],\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 50 diverse tuple combinations of the dimensions:\n",
      "\n",
      "1.  ('Breakfast', 'Not spicy', '10 minutes')\n",
      "2.  ('Lunch', 'Vegetarian', '30 minutes')\n",
      "3.  ('Dinner', 'Meaty', 'Under 1 hour')\n",
      "4.  ('Snack', 'Gluten-free', 'Quick')\n",
      "5.  ('Dessert', 'Dairy-free', '45 minutes')\n",
      "6.  ('Brunch', 'Vegan', 'I have all the time until retirement')\n",
      "7.  ('Appetizer', 'Low-carb', '15 minutes')\n",
      "8.  ('Side Dish', 'High-protein', '20 minutes')\n",
      "9.  ('Lite breakfast', 'Kid-friendly', 'Less than 20 minutes')\n",
      "10. ('Holiday meal', 'Pescatarian', 'All day')\n",
      "11. ('Party food', 'Sugar-free', 'About an hour')\n",
      "12. ('Quick bite', 'Nut-free', 'Instant')\n",
      "13. ('Breakfast', 'Keto', '30 minutes')\n",
      "14. ('Lunch', 'Heart-healthy', 'Under 1 hour')\n",
      "15. ('Dinner', 'Spicy', '45 minutes')\n",
      "16. ('Snack', 'without fish or meat', '10 minutes')\n",
      "17. ('Dessert', 'Meaty', 'Long prep')\n",
      "18. ('Brunch', 'Paleo', 'Quick')\n",
      "19. ('Appetizer', 'Low-salt', '15 minutes')\n",
      "20. ('Side Dish', 'Diabetic-friendly', '20 minutes')\n",
      "21. ('Lite breakfast', 'High-fiber', 'Less than 20 minutes')\n",
      "22. ('Holiday meal', 'Lactose-free', 'Overnight')\n",
      "23. ('Party food', 'Comfort food', 'About an hour')\n",
      "24. ('Quick bite', 'with hummus and carrots', 'Instant')\n",
      "25. ('Breakfast', 'Gluten-free', 'Quick and easy')\n",
      "26. ('Lunch', 'Vegan', '30 minutes')\n",
      "27. ('Dinner', 'High-protein', 'Under 1 hour')\n",
      "28. ('Snack', 'Not spicy', '10 minutes')\n",
      "29. ('Dessert', 'Vegetarian', '45 minutes')\n",
      "30. ('Brunch', 'Meaty', 'I have all the time until retirement')\n",
      "31. ('Appetizer', 'Dairy-free', '15 minutes')\n",
      "32. ('Side Dish', 'Low-carb', '20 minutes')\n",
      "33. ('Lite breakfast', 'Pescatarian', 'Less than 20 minutes')\n",
      "34. ('Holiday meal', 'Kid-friendly', 'All day')\n",
      "35. ('Party food', 'Nut-free', 'About an hour')\n",
      "36. ('Quick bite', 'Sugar-free', 'Instant')\n",
      "37. ('Breakfast', 'Spicy', 'Quick and easy')\n",
      "38. ('Lunch', 'Keto', '30 minutes')\n",
      "39. ('Dinner', 'Heart-healthy', 'Under 1 hour')\n",
      "40. ('Snack', 'Low-salt', '10 minutes')\n",
      "41. ('Dessert', 'Diabetic-friendly', '45 minutes')\n",
      "42. ('Brunch', 'High-fiber', 'Long prep')\n",
      "43. ('Appetizer', 'Lactose-free', '15 minutes')\n",
      "44. ('Side Dish', 'Comfort food', '20 minutes')\n",
      "45. ('Lite breakfast', 'Paleo', 'Less than 20 minutes')\n",
      "46. ('Holiday meal', 'with hummus and carrots', 'Overnight')\n",
      "47. ('Party food', 'Not spicy', 'About an hour')\n",
      "48. ('Quick bite', 'Vegetarian', 'Instant')\n",
      "49. ('Dinner', 'Gluten-free', '10 minutes')\n",
      "50. ('Lunch', 'Meaty', 'something quick')\n"
     ]
    }
   ],
   "source": [
    "dimention_list = generate_dimention_list(\"\")\n",
    "\n",
    "print(dimention_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimention_tuples = [\n",
    "    ('Breakfast', 'Not spicy', '10 minutes'),\n",
    "    ('Lunch', 'Vegetarian', '30 minutes'),\n",
    "    ('Dinner', 'Meaty', 'Under 1 hour'),\n",
    "    ('Snack', 'Gluten-free', 'Quick'),\n",
    "    ('Dessert', 'Dairy-free', '45 minutes'),\n",
    "    ('Brunch', 'Vegan', 'I have all the time until retirement'),\n",
    "    ('Appetizer', 'Low-carb', '15 minutes'),\n",
    "    ('Side Dish', 'High-protein', '20 minutes'),\n",
    "    ('Lite breakfast', 'Kid-friendly', 'Less than 20 minutes'),\n",
    "    ('Holiday meal', 'Pescatarian', 'All day'),\n",
    "    ('Party food', 'Sugar-free', 'About an hour'),\n",
    "    ('Quick bite', 'Nut-free', 'Instant'),\n",
    "    ('Breakfast', 'Keto', '30 minutes'),\n",
    "    ('Lunch', 'Heart-healthy', 'Under 1 hour'),\n",
    "    ('Dinner', 'Spicy', '45 minutes'),\n",
    "    ('Snack', 'without fish or meat', '10 minutes'),\n",
    "    ('Dessert', 'Meaty', 'Long prep'),\n",
    "    ('Brunch', 'Paleo', 'Quick'),\n",
    "    ('Appetizer', 'Low-salt', '15 minutes'),\n",
    "    ('Side Dish', 'Diabetic-friendly', '20 minutes'),\n",
    "    ('Lite breakfast', 'High-fiber', 'Less than 20 minutes'),\n",
    "    ('Holiday meal', 'Lactose-free', 'Overnight'),\n",
    "    ('Party food', 'Comfort food', 'About an hour'),\n",
    "    ('Quick bite', 'with hummus and carrots', 'Instant'),\n",
    "    ('Breakfast', 'Gluten-free', 'Quick and easy'),\n",
    "    ('Lunch', 'Vegan', '30 minutes'),\n",
    "    ('Dinner', 'High-protein', 'Under 1 hour'),\n",
    "    ('Snack', 'Not spicy', '10 minutes'),\n",
    "    ('Dessert', 'Vegetarian', '45 minutes'),\n",
    "    ('Brunch', 'Meaty', 'I have all the time until retirement'),\n",
    "    ('Appetizer', 'Dairy-free', '15 minutes'),\n",
    "    ('Side Dish', 'Low-carb', '20 minutes'),\n",
    "    ('Lite breakfast', 'Pescatarian', 'Less than 20 minutes'),\n",
    "    ('Holiday meal', 'Kid-friendly', 'All day'),\n",
    "    ('Party food', 'Nut-free', 'About an hour'),\n",
    "    ('Quick bite', 'Sugar-free', 'Instant'),\n",
    "    ('Breakfast', 'Spicy', 'Quick and easy'),\n",
    "    ('Lunch', 'Keto', '30 minutes'),\n",
    "    ('Dinner', 'Heart-healthy', 'Under 1 hour'),\n",
    "    ('Snack', 'Low-salt', '10 minutes'),\n",
    "    ('Dessert', 'Diabetic-friendly', '45 minutes'),\n",
    "    ('Brunch', 'High-fiber', 'Long prep'),\n",
    "    ('Appetizer', 'Lactose-free', '15 minutes'),\n",
    "    ('Side Dish', 'Comfort food', '20 minutes'),\n",
    "    ('Lite breakfast', 'Paleo', 'Less than 20 minutes'),\n",
    "    ('Holiday meal', 'with hummus and carrots', 'Overnight'),\n",
    "    ('Party food', 'Not spicy', 'About an hour'),\n",
    "    ('Quick bite', 'Vegetarian', 'Instant'),\n",
    "    ('Dinner', 'Gluten-free', '10 minutes'),\n",
    "    ('Lunch', 'Meaty', 'something quick'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def call_llm(dimention: str):\n",
    "    prompt = f\"\"\"\n",
    "        You are AI assisntant that helps to generate user queryies for a recipe chatbot.\n",
    "        You will be given a list of tuples, that describe dimentions for a user query. Given these dimentions, generate 4-5 user queries. \n",
    "\n",
    "        <dimension>\n",
    "        {dimention_list}\n",
    "        </dimension>\n",
    "\n",
    "        <example>\n",
    "        <dimension>\n",
    "        ('Breakfast', 'Not spicy', '10 minutes')\n",
    "        </dimension>\n",
    "\n",
    "        - I want to make a quick breakfast that is not spicy and takes 10 minutes to prepare.\n",
    "        - Give me a quick recipe for plain breakfast. \n",
    "        - Breakfast, fast and non-spicy.\n",
    "        - A ten-minute breakfast meal, non-spicy.\n",
    "        - I need breakfast under 10 minutes, it should be mild to taste. \n",
    "        </example>\n",
    "\n",
    "        Just output user queries, no other text.\n",
    "    \"\"\"\n",
    "    completion = litellm.completion(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {\n  \"error\": {\n    \"code\": 429,\n    \"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\",\n    \"status\": \"RESOURCE_EXHAUSTED\",\n    \"details\": [\n      {\n        \"@type\": \"type.googleapis.com/google.rpc.QuotaFailure\",\n        \"violations\": [\n          {\n            \"quotaMetric\": \"generativelanguage.googleapis.com/generate_content_free_tier_requests\",\n            \"quotaId\": \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\",\n            \"quotaDimensions\": {\n              \"model\": \"gemini-2.5-flash\",\n              \"location\": \"global\"\n            },\n            \"quotaValue\": \"10\"\n          }\n        ]\n      },\n      {\n        \"@type\": \"type.googleapis.com/google.rpc.Help\",\n        \"links\": [\n          {\n            \"description\": \"Learn more about Gemini API quotas\",\n            \"url\": \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n          }\n        ]\n      },\n      {\n        \"@type\": \"type.googleapis.com/google.rpc.RetryInfo\",\n        \"retryDelay\": \"20s\"\n      }\n    ]\n  }\n}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPStatusError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/recipe-chatbot/.venv/lib/python3.12/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py:1711\u001b[39m, in \u001b[36mVertexLLM.completion\u001b[39m\u001b[34m(self, model, messages, model_response, print_verbose, custom_llm_provider, encoding, logging_obj, optional_params, acompletion, timeout, vertex_project, vertex_location, vertex_credentials, gemini_api_key, litellm_params, logger_fn, extra_headers, client, api_base)\u001b[39m\n\u001b[32m   1710\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1711\u001b[39m     response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m   1712\u001b[39m     response.raise_for_status()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/recipe-chatbot/.venv/lib/python3.12/site-packages/litellm/llms/custom_httpx/http_handler.py:704\u001b[39m, in \u001b[36mHTTPHandler.post\u001b[39m\u001b[34m(self, url, data, json, params, headers, stream, timeout, files, content, logging_obj)\u001b[39m\n\u001b[32m    703\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mstatus_code\u001b[39m\u001b[33m\"\u001b[39m, e.response.status_code)\n\u001b[32m--> \u001b[39m\u001b[32m704\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/recipe-chatbot/.venv/lib/python3.12/site-packages/litellm/llms/custom_httpx/http_handler.py:686\u001b[39m, in \u001b[36mHTTPHandler.post\u001b[39m\u001b[34m(self, url, data, json, params, headers, stream, timeout, files, content, logging_obj)\u001b[39m\n\u001b[32m    685\u001b[39m response = \u001b[38;5;28mself\u001b[39m.client.send(req, stream=stream)\n\u001b[32m--> \u001b[39m\u001b[32m686\u001b[39m \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/recipe-chatbot/.venv/lib/python3.12/site-packages/httpx/_models.py:829\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    828\u001b[39m message = message.format(\u001b[38;5;28mself\u001b[39m, error_type=error_type)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request=request, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPStatusError\u001b[39m: Client error '429 Too Many Requests' for url 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=AIzaSyDoGN4ExkfA7WXZkp_9-ORdTt4C9fCPifE'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mVertexAIError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/recipe-chatbot/.venv/lib/python3.12/site-packages/litellm/main.py:2469\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[39m\n\u001b[32m   2468\u001b[39m     new_params = deepcopy(optional_params)\n\u001b[32m-> \u001b[39m\u001b[32m2469\u001b[39m     response = \u001b[43mvertex_chat_completion\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m   2470\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2471\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2472\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2473\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprint_verbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2474\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptional_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2475\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m   2476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogger_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogger_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvertex_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvertex_ai_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvertex_project\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvertex_ai_project\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvertex_credentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvertex_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgemini_api_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgemini_api_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2483\u001b[39m \u001b[43m        \u001b[49m\u001b[43macompletion\u001b[49m\u001b[43m=\u001b[49m\u001b[43macompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2485\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2486\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2487\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2488\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2489\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2491\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m custom_llm_provider == \u001b[33m\"\u001b[39m\u001b[33mvertex_ai\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/recipe-chatbot/.venv/lib/python3.12/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py:1715\u001b[39m, in \u001b[36mVertexLLM.completion\u001b[39m\u001b[34m(self, model, messages, model_response, print_verbose, custom_llm_provider, encoding, logging_obj, optional_params, acompletion, timeout, vertex_project, vertex_location, vertex_credentials, gemini_api_key, litellm_params, logger_fn, extra_headers, client, api_base)\u001b[39m\n\u001b[32m   1714\u001b[39m     error_code = err.response.status_code\n\u001b[32m-> \u001b[39m\u001b[32m1715\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m VertexAIError(\n\u001b[32m   1716\u001b[39m         status_code=error_code,\n\u001b[32m   1717\u001b[39m         message=err.response.text,\n\u001b[32m   1718\u001b[39m         headers=err.response.headers,\n\u001b[32m   1719\u001b[39m     )\n\u001b[32m   1720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException:\n",
      "\u001b[31mVertexAIError\u001b[39m: {\n  \"error\": {\n    \"code\": 429,\n    \"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\",\n    \"status\": \"RESOURCE_EXHAUSTED\",\n    \"details\": [\n      {\n        \"@type\": \"type.googleapis.com/google.rpc.QuotaFailure\",\n        \"violations\": [\n          {\n            \"quotaMetric\": \"generativelanguage.googleapis.com/generate_content_free_tier_requests\",\n            \"quotaId\": \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\",\n            \"quotaDimensions\": {\n              \"model\": \"gemini-2.5-flash\",\n              \"location\": \"global\"\n            },\n            \"quotaValue\": \"10\"\n          }\n        ]\n      },\n      {\n        \"@type\": \"type.googleapis.com/google.rpc.Help\",\n        \"links\": [\n          {\n            \"description\": \"Learn more about Gemini API quotas\",\n            \"url\": \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n          }\n        ]\n      },\n      {\n        \"@type\": \"type.googleapis.com/google.rpc.RetryInfo\",\n        \"retryDelay\": \"20s\"\n      }\n    ]\n  }\n}\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m tuple_to_queries = defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m dimention \u001b[38;5;129;01min\u001b[39;00m dimention_tuples:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     query = \u001b[43mcall_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdimention\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     tuple_to_queries[dimention].append(query)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mcall_llm\u001b[39m\u001b[34m(dimention)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_llm\u001b[39m(dimention: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m      2\u001b[39m     prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33m        You are AI assisntant that helps to generate user queryies for a recipe chatbot.\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[33m        You will be given a list of tuples, that describe dimentions for a user query. Given these dimentions, generate 4-5 user queries. \u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m \u001b[33m        Just output user queries, no other text.\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[33m    \u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     completion = \u001b[43mlitellm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m completion.choices[\u001b[32m0\u001b[39m].message.content\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/recipe-chatbot/.venv/lib/python3.12/site-packages/litellm/utils.py:1285\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1281\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m logging_obj:\n\u001b[32m   1282\u001b[39m     logging_obj.failure_handler(\n\u001b[32m   1283\u001b[39m         e, traceback_exception, start_time, end_time\n\u001b[32m   1284\u001b[39m     )  \u001b[38;5;66;03m# DO NOT MAKE THREADED - router retry fallback relies on this!\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1285\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/recipe-chatbot/.venv/lib/python3.12/site-packages/litellm/utils.py:1163\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1161\u001b[39m         print_verbose(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError while checking max token limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1162\u001b[39m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1163\u001b[39m result = \u001b[43moriginal_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1164\u001b[39m end_time = datetime.datetime.now()\n\u001b[32m   1165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m kwargs[\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/recipe-chatbot/.venv/lib/python3.12/site-packages/litellm/main.py:3264\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[39m\n\u001b[32m   3261\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[32m   3262\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   3263\u001b[39m     \u001b[38;5;66;03m## Map to OpenAI Exception\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3264\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mexception_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3267\u001b[39m \u001b[43m        \u001b[49m\u001b[43moriginal_exception\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3269\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3270\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/recipe-chatbot/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:2239\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m   2237\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m exception_mapping_worked:\n\u001b[32m   2238\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mlitellm_response_headers\u001b[39m\u001b[33m\"\u001b[39m, litellm_response_headers)\n\u001b[32m-> \u001b[39m\u001b[32m2239\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   2240\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2241\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m error_type \u001b[38;5;129;01min\u001b[39;00m litellm.LITELLM_EXCEPTION_TYPES:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/recipe-chatbot/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:1276\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m   1274\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m original_exception.status_code == \u001b[32m429\u001b[39m:\n\u001b[32m   1275\u001b[39m     exception_mapping_worked = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1276\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RateLimitError(\n\u001b[32m   1277\u001b[39m         message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mlitellm.RateLimitError: VertexAIException - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1278\u001b[39m         model=model,\n\u001b[32m   1279\u001b[39m         llm_provider=\u001b[33m\"\u001b[39m\u001b[33mvertex_ai\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1280\u001b[39m         litellm_debug_info=extra_information,\n\u001b[32m   1281\u001b[39m         response=httpx.Response(\n\u001b[32m   1282\u001b[39m             status_code=\u001b[32m429\u001b[39m,\n\u001b[32m   1283\u001b[39m             request=httpx.Request(\n\u001b[32m   1284\u001b[39m                 method=\u001b[33m\"\u001b[39m\u001b[33mPOST\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1285\u001b[39m                 url=\u001b[33m\"\u001b[39m\u001b[33m https://cloud.google.com/vertex-ai/\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1286\u001b[39m             ),\n\u001b[32m   1287\u001b[39m         ),\n\u001b[32m   1288\u001b[39m     )\n\u001b[32m   1289\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m original_exception.status_code == \u001b[32m500\u001b[39m:\n\u001b[32m   1290\u001b[39m     exception_mapping_worked = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mRateLimitError\u001b[39m: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {\n  \"error\": {\n    \"code\": 429,\n    \"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\",\n    \"status\": \"RESOURCE_EXHAUSTED\",\n    \"details\": [\n      {\n        \"@type\": \"type.googleapis.com/google.rpc.QuotaFailure\",\n        \"violations\": [\n          {\n            \"quotaMetric\": \"generativelanguage.googleapis.com/generate_content_free_tier_requests\",\n            \"quotaId\": \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\",\n            \"quotaDimensions\": {\n              \"model\": \"gemini-2.5-flash\",\n              \"location\": \"global\"\n            },\n            \"quotaValue\": \"10\"\n          }\n        ]\n      },\n      {\n        \"@type\": \"type.googleapis.com/google.rpc.Help\",\n        \"links\": [\n          {\n            \"description\": \"Learn more about Gemini API quotas\",\n            \"url\": \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n          }\n        ]\n      },\n      {\n        \"@type\": \"type.googleapis.com/google.rpc.RetryInfo\",\n        \"retryDelay\": \"20s\"\n      }\n    ]\n  }\n}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "tuple_to_queries = defaultdict(list)\n",
    "for dimention in dimention_tuples:\n",
    "    query = call_llm(dimention)\n",
    "    tuple_to_queries[dimention].append(query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {('Breakfast',\n",
       "              'Not spicy',\n",
       "              '10 minutes'): ['- I need a vegetarian lunch recipe that takes about 30 minutes.\\n- What can I cook for a quick vegetarian lunch in half an hour?\\n- Suggest some vegetarian lunch ideas for a 30-minute prep time.\\n- Looking for a 30-minute vegetarian lunch.\\n- Lunch recipe, vegetarian, 30 min max.'],\n",
       "             ('Lunch',\n",
       "              'Vegetarian',\n",
       "              '30 minutes'): [\"- I'm looking for a vegetarian lunch recipe that I can make in 30 minutes.\\n- Can you suggest some quick vegetarian lunch ideas for around 30 minutes?\\n- Vegetarian lunch, 30 min prep time.\\n- What's a good vegetarian lunch I can whip up in half an hour?\\n- Need a fast vegetarian lunch recipe, 30 minutes tops.\"]})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple_to_queries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
